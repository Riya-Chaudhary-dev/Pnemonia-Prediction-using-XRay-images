{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization, Activation\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport os\nimport random\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size=150\ndata=[]\nassign_dict = {\"NORMAL\":1, \"PNEUMONIA\":0}\ndef load_data(directory):\n    for sub_directory in os.listdir(directory):\n        if sub_directory==\"NORMAL\":\n            inner_directory=os.path.join(directory,sub_directory)\n            for i in os.listdir(inner_directory):\n                img=cv2.imread(os.path.join(inner_directory,i),0)\n                img=cv2.resize(img,(size,size))\n                data.append([img,assign_dict[sub_directory]])\n                \n        if sub_directory==\"PNEUMONIA\":\n            inner_directory=os.path.join(directory,sub_directory)\n            for i in os.listdir(inner_directory):\n                img=cv2.imread(os.path.join(inner_directory,i),0)\n                img=cv2.resize(img,(size,size))\n                data.append([img,assign_dict[sub_directory]])        \n            \n    random.shuffle(data)\n    return np.array(data)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=load_data('../input/chest-xray-pneumonia/chest_xray/train')\nval = load_data('../input/chest-xray-pneumonia/chest_xray/val')\ntest = load_data('../input/chest-xray-pneumonia/chest_xray/test')","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = []\nfor i in train:\n    if(i[1] == 0):\n        l.append(\"Pneumonia\")\n    else:\n        l.append(\"Normal\")\nsns.countplot(x = l)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<AxesSubplot:ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## The dataset is imbalanced thus using data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\nfor feature, label in train:\n    x_train.append(feature)\n    y_train.append(label)\n\nfor feature, label in test:\n    x_test.append(feature)\n    y_test.append(label)\n    \nfor feature, label in val:\n    x_val.append(feature)\n    y_val.append(label)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\nx_train = np.array(x_train) / 255\nx_val = np.array(x_val) / 255\nx_test = np.array(x_test) / 255","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resize data for deep learning \nimg_size = 150\nx_train = x_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val = x_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n\nx_test = x_test.reshape(-1, img_size, img_size, 1)\ny_test = np.array(y_test)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape=x_train.shape[1:]))\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.1))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Flatten())\n\nmodel.add(Dense(units = 128 , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))\nadam = Adam(learning_rate=0.0001)\n\nmodel.compile(optimizer = adam,metrics=['acc'] , loss = 'binary_crossentropy' )\nmodel.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_4 (Conv2D)            (None, 150, 150, 64)      640       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 75, 75, 64)        0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 75, 75, 64)        300       \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 75, 75, 32)        18464     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 75, 75, 32)        0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 75, 75, 32)        300       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 38, 38, 32)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 38, 38, 128)       36992     \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 38, 38, 128)       152       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 19, 19, 128)       0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 19, 19, 64)        73792     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 19, 19, 64)        0         \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 19, 19, 64)        76        \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 10, 10, 64)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 10, 10, 256)       147712    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 10, 10, 256)       0         \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 10, 10, 256)       40        \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 5, 5, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6400)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               819328    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 1,097,925\nTrainable params: 1,097,491\nNon-trainable params: 434\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,epochs = 20 , validation_data = datagen.flow(x_val, y_val) ,callbacks = [learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\n\n\nfor i, met in enumerate(['acc', 'loss','val_acc','val_loss']):\n    ax[i].plot(history.history[met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(x_test)\npredictions = predictions.reshape(1,-1)[0]\npredictions[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,predictions)\nplt.figure(figsize = (10,10))\nsns.heatmap(cm, linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = ['PNEUMONIA', 'NORMAL'], yticklabels =  ['PNEUMONIA', 'NORMAL'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}